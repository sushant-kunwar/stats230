---
title: "Final Project"
author: "Funny Guys"
output:
  word_document: 
    reference_docx:
    fig_height: 5
    fig_width: 8
  html_document: default
date: "2024-04-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
States <- read.csv("/Users/sushantkunwar/Downloads/archive (1)/states_all_extended.csv")
```


```{r, message = FALSE}
library(car)
library(leaps)
library(lubridate)
library(rvest)
library(olsrr)
library(corrplot)
library(leaps)
library(MASS)
source("http://www.reuningscherer.net/s&ds230/Rfuncs/regJDRS.txt")
```

# INTRODUCTION

This project delves into an extensive data set, capturing a range of educational metrics across various U.S. states from the years 1992 and 2015, focusing on financial, demographic, and academic performance indicators. By comparing changes over these years, the project aims to shed light on trends and shifts in education funding, resource allocation, and student performance. Critical data points such as student enrollment figures, total revenue and expenditures for education, instructional expenditures, and standardized test scores in mathematics are analyzed to understand their interrelations and impact on educational outcomes. The introduction of calculated variables like proportional instruction expenditure and gender-specific performance differences further enriches the analysis, providing deeper insights into the dynamics of educational equity and efficacy over the observed period.

# DATA
The data we used for this project can be found [here](https://www.kaggle.com/datasets/noriuk/us-education-datasets-unification-project?resource=download). This data set was created by aggregating financial data from the US Census, enrollment data from the National Center for Education Statistics, and academic achievement data from the National Assessment of Educational Progress. 

# VARIABLES

## Continuous Variables:
**ENROLLMENT**: This variable represents the maximum count of students from two different sources, namely "ENROLL" and "A_A_A." It consolidates data from these sources to provide a more comprehensive picture of student enrollment in the state.

**TOTAL_REVENUE**: This variable denotes the total amount of revenue generated by the state's educational system, in dollars. It encompasses various funding sources, including federal, state, and local contributions.

**TOTAL_EXPENDITURE**: This variable represents the total expenditure incurred by the state's educational system, covering expenses such as salaries, facilities maintenance, and program funding. It's a measure of the financial resources allocated to education within the state.

**INSTRUCTION_EXPENDITURE**: This variable specifically refers to the portion of total expenditure dedicated to instructional activities, including teacher salaries, classroom materials, and curriculum development. It highlights the investment made in direct educational services.

**PROP_INSTR_EXP**: This variable is derived by dividing the instruction expenditure by the total expenditure, resulting in the proportion of total expenditure allocated to instructional activities. It provides insight into the budget allocation, emphasizing the relative importance of instruction within the overall education budget.

**AVG_MATH**: This variable represents the average math score, out of 500, of eighth-grade students within the state. 

**AVG_MATH_M**: This variable indicates the average math score, out of 500, for eighth-grade students classified as "male." 

**AVG_MATH_F**: This variable denotes the average math score, out of 500, for eighth-grade students classified as "female." 

**MATH_GENDER_DIF**: This variable is calculated as the difference between the average math scores of male and female eighth-grade students. It quantifies the disparity or gap in math performance between genders within the state.

**SCORE_ASIAN**: This variable represents the average math score, out of 500, of eighth-grade students who identify as Asian.

**SCORE_NATIVE_AM**: This variable denotes the average math score, out of 500, of eighth-grade students who identify as Native American.

**SCORE_HISPANIC_LATINO**: This variable signifies the average math score, out of 500, of eighth-grade students who identify as Hispanic or Latino.

**SCORE_BLACK**: This variable indicates the average math score, out of 500, of eighth-grade students who identify as Black or African American.

**SCORE_WHITE**: This variable represents the average math score, out of 500, of eighth-grade students who identify as White.

**SCORE_HAWAIIAN_PI**: This variable denotes the average math score, out of 500, of eighth-grade students who identify as Hawaiian or Pacific Islander.

**SCORE_MULTIPLE_RACES**: This variable represents the average math score, out of 500, of eighth-grade students who identify as two or more races.

## Categorical Variables
**YEAR**: This variable indicates the year to which the data corresponds. It serves as a categorical identifier for different time periods within the dataset.

**STATE**: This variable represents the state from which the data is sourced. It categorizes the observations based on geographic location, allowing for comparisons and analyses across different states.


# Data Cleaning
The cleaning process for the dataset began by creating a unified enrollment column, **ENROLLMENT**, by selecting the maximum value between two existing columns, **ENROLL** and **A_A_A**, which represented student counts from different sources. This step ensured consistency and completeness in student enrollment data. Next, a new variable, **PROP_INSTRUCTION_EXPENDITURE**, was calculated by dividing the **INSTRUCTION_EXPENDITURE** by the **TOTAL_EXPENDITURE**, providing insight into the proportion of total expenditure allocated to instruction. Another new variable, **MATH_GENDER_DIF**, was created to capture the difference between male and female math scores in grade 8, derived from existing columns. Additionally, variable names were standardized and simplified for clarity and consistency. The process also involved renaming several variables for clarity and consistency. The new names were more descriptive names compared to their original counterparts, facilitating easier interpretation and analysis of the dataset. To get an in depth look at the renaming process please look into the r-MARKDOWN file. Two separate data frames, **States1992** and **States2015**, were then created to isolate data from 1992 and 2015, respectively, for focused analysis. The rows in these data frames were labeled with state names to facilitate identification and interpretation. Furthermore, columns containing all NA values were removed to ensure data quality and reduce redundancy. Overall, these cleaning steps aimed to prepare the dataset for subsequent analysis by addressing missing values, standardizing variable names, and organizing the data for comparative analysis between the two selected years, 1992 and 2015.




```{r echo = F}

#Creating a Unified ENROLLMENT column by taking the max of 2 Columns with data from different sources(ENROLL & A_A_A)
States$ENROLLMENT <- pmax(States$A_A_A, States$ENROLL, na.rm = T)


#New Variable: Proportional Instruction Expenditure
States$PROP_INSTRUCTION_EXPENDITURE <- States$INSTRUCTION_EXPENDITURE / States$TOTAL_EXPENDITURE

#New Variable: Difference between Male and Female Math Scores in Grade 8(M-F)
States$MATH_GENDER_DIF <- States$G08_A_M_MATHEMATICS - States$G08_A_F_MATHEMATICS

#Rename Variables:
States$AVG_MATH <- States$G08_A_A_MATHEMATICS
States$AVG_MATH_M <- States$G08_A_M_MATHEMATICS
States$AVG_MATH_F <- States$G08_A_F_MATHEMATICS
States$SCORE_ASIAN <- States$G08_AM_A_MATHEMATICS
States$SCORE_NATIVE_AM <- States$G08_AS_A_MATHEMATICS
States$SCORE_HISPANIC_LATINO <- States$G08_HI_A_MATHEMATICS
States$SCORE_BLACK <- States$G08_BL_A_MATHEMATICS
States$SCORE_WHITE <- States$G08_WH_A_MATHEMATICS
States$SCORE_HAWAIIAN_PI <- States$G08_HP_A_MATHEMATICS
States$SCORE_MULTIPLE_RACES <- States$G08_TR_A_MATHEMATICS

#Creating a data frame for data from just 1992
States1992 <- States[c(1:51), ]


#Creating a data frame for data from just 2016
States2015 <- States[c(1174:1224), ]


#making the row numbers the state name 1992
rownames(States1992) <- States1992$STATE

#Removing the PRIMARY_KEY and STATE columns as it'll be redundant/confusing later 1992
States1992 <- States1992[ ,-1]
#States1992 <- States1992[ ,-1]


#making the row numbers the state name 2015
rownames(States2015) <- States2015$STATE

#Removing the PRIMARY_KEY and STATE columns as it'll be redundant/confusing later 2015
States2015 <- States2015[ ,-1]
#States2015 <- States2015[ ,-1]


#Removing Columns with all NAs
States1992 <- States1992[ ,colSums(is.na(States1992)) < nrow(States1992)]


States2015 <- States2015[ ,colSums(is.na(States2015)) < nrow(States2015)]


```


```{r}
get_region <- function(state_name) {
  regions <- list(
    Northeast = c("maine", "new_hampshire", "vermont", "massachusetts", "rhode_island", "connecticut", "new_york", "new_jersey", "pennsylvania"),
    Midwest = c("ohio", "indiana", "illinois", "michigan", "wisconsin", "minnesota", "iowa", "missouri", "north_dakota", "south_dakota", "nebraska", "kansas"),
    South = c("delaware", "maryland", "district_of_columbia", "virginia", "west_virginia", "north_carolina", "south_carolina", "georgia", "florida", "kentucky", "tennessee", "alabama", "mississippi", "arkansas", "louisiana", "texas", "oklahoma"),
    West = c("montana", "idaho", "wyoming", "colorado", "new_mexico", "arizona", "utah", "nevada", "california", "oregon", "washington", "alaska", "hawaii")
  )
  
  state_name <- tolower(state_name)
  
  for (region in names(regions)) {
    if (state_name %in% regions[[region]]) {
      return(region)
    }
  }
  
  return(NA)
}

# Apply the function to create the new column in your dataset
States2015$Region <- sapply(rownames(States2015), get_region)
View(States2015)
```



# Analyzing State Expenditure and Average Math Scores
## Descriptive Plots
```{r, echo=FALSE}
#Scatter plot comparing total instruction expenditure and avg math score (1992 and 2015)
plot(States1992$AVG_MATH ~ States1992$INSTRUCTION_EXPENDITURE, ylab = "Average Math Score", main = "Plot of Total  Expenditure on Instruction vs Avg Math Score in 1992", xlab = "Total Expenditure(Dollars)", pch = 19, cex.main = 0.7, col = "lightblue")
abline(lm(States1992$AVG_MATH ~ States1992$INSTRUCTION_EXPENDITURE), col = "red", lwd = 3)

plot(States2015$AVG_MATH ~ States2015$INSTRUCTION_EXPENDITURE, ylab = "Average Math Score", main = "Plot of Total Expenditure on Instruction vs Avg Math Score in 2015", xlab = "Total Expenditure(Dollars)", pch = 19, cex.main = 0.7, col = "darkblue")
abline(lm(States2015$AVG_MATH ~ States2015$INSTRUCTION_EXPENDITURE), col = "red", lwd = 3)

```

The first scatter plot shows the relationship between total expenditure on instruction and average math score in 1992. There appears to be a positive correlation, with higher expenditures generally associated with higher average math scores, though the relationship is not perfectly linear. Specifically, most of the data points are concentrated in the upper-left of the plot, further hinting at the fact that this relationship is not linear.

The second scatter plot displays the same variables as the previous one, but for the year 2015. Here, there is a similar issue where the data does not appear linear and is concentrated in the upper left of the plot. To get some further clarification on this information, we run correlations tests to see how strong the correlation is between these two values between the two years.

```{r}

corr1992 <- cor(States1992$AVG_MATH, States1992$INSTRUCTION_EXPENDITURE, use = "complete.obs")
corr2015 <- cor(States2015$AVG_MATH, States2015$INSTRUCTION_EXPENDITURE, use = "complete.obs")
print('Correlation between Average Math Scores and Instruction Expenditure in 1992:')
corr1992
print('Correlation between Average Math Scores and Instruction Expenditure in 2015:')
corr2015

```

It seems like the correlation coefficients for both 1992 and 2015 are very close to zero, indicating a very weak linear relationship between average math scores and instruction expenditure in both years. This suggests that there may not be a strong linear association between these variables, at least not one that is captured by the correlation coefficient alone. This suggests that we should use the proportional expenditure on instruction rather than just pure expenditure on instruction.

```{r}
#Scatter plot comparing proportional expenditure and avg math score (1992 and 2015)
plot(States1992$AVG_MATH ~ States1992$PROP_INSTRUCTION_EXPENDITURE, ylab = "Average Math Score", main = "Plot of Proportional Expenditure on Instruction vs Avg Math Score in 1992", xlab = "Proportional Expenditure", pch = 19, cex.main = 0.7, col = "lightblue")
abline(lm(States1992$AVG_MATH ~ States1992$PROP_INSTRUCTION_EXPENDITURE), col = "red", lwd = 3)


plot(States2015$AVG_MATH ~ States2015$PROP_INSTRUCTION_EXPENDITURE, ylab = "Average Math Score", main = "Plot of Proportional Expenditure on Instruction vs Avg Math Score in 2015", xlab = "Proportional Expenditure", pch = 19, cex.main = 0.7, col = "darkblue")
abline(lm(States2015$AVG_MATH ~ States2015$PROP_INSTRUCTION_EXPENDITURE), col = "red", lwd = 3)
```

This first scatter plot displays the relationship between the proportional expenditure on instruction and average math score in 1992. Unlike the plot displaying the total expenditure, there is a positive correlation. In this graph then correlation is much more pronounced and is more linear. Here we can see that, generally when a higher proportion of the budget goes to instruction, we would expect that the average math score would increase.

The variables in the second plot are the same as the previous plot, this plot just focuses on 2015. Just like the previous plot, this one demonstrates how we should take into account the proportion of the total expenditure that goes to instruction rather than just the total expenditure on instruction. The different sizes of different states will skew the data if we only focus on the total expenditure on instruction. We see a slight positive correlation in this plot.

```{r}
corr1992 <- cor(States1992$AVG_MATH, States1992$PROP_INSTRUCTION_EXPENDITURE, use = "complete.obs")
corr2015 <- cor(States2015$AVG_MATH, States2015$PROP_INSTRUCTION_EXPENDITURE, use = "complete.obs")
print('Correlation between Average Math Scores and Instruction Expenditure in 1992:')
corr1992
print('Correlation between Average Math Scores and Instruction Expenditure in 2015:')
corr2015

```
The correlation coefficients between average math scores and proportional instruction expenditure for both 1992 and 2015 are 0.1828254 and 0.2694149, respectively. These coefficients suggest a positive but relatively weak linear relationship between these variables in both years. In 1992, the correlation coefficient indicates that there was a decent positive association between proportional instruction expenditure and average math scores, implying that states with a higher proportion of their total expenditure allocated to instruction tended to have slightly higher average math scores. Similarly, in 2015, the correlation coefficient indicates a slightly stronger positive relationship, suggesting that the proportion of total expenditure allocated to instruction was more closely associated with higher average math scores. However, it's important to also note that correlation doesn't imply causation, and other factors not captured by this analysis may also influence average math scores.

## Tests
```{r}
#Bootstrapped Confidence Interval Between Proportional Expenditures and MATH AVG SCORES
N <- 51
n_samp <- 10000

corResults1992 <- rep(NA, n_samp)
corResults2015 <- rep(NA, n_samp)

for(i in 1:n_samp){
  #get vector of rows in our fake sample
  s <- sample(1:N, N , replace = T)
  data1992 <- na.omit(States1992[s, ])
  data2015 <- States2015[s, ]
    
  #Get bootstrapped correlation and regression slope
  
  corResults1992[i] <- cor(data1992$PROP_INSTRUCTION_EXPENDITURE, data1992$AVG_MATH)
  corResults2015[i] <- cor(data2015$PROP_INSTRUCTION_EXPENDITURE, data2015$AVG_MATH)
}
ci1992 <- quantile(corResults1992, c(.025, .975), na.rm = T)
ci2015 <- quantile(corResults2015, c(.025, .975), na.rm = T)

print("1992 BootStrapped Correlations")
ci1992
print("2015 BootStrapped Correlations")
ci2015
```
These are the results from our bootstrapped confidence intervals for correlations between proportional expenditures and average math scores in 1992 and 2015. For 1992, the bootstrapped correlation is estimated to lie between -0.1590 and 0.4828 with a 95% confidence level. In 2015, the bootstrapped correlation is estimated to range from -0.0352 to 0.5304 with the same confidence level. These intervals signify the range of plausible values for the correlation coefficients based on resampling from the data. The wider interval in 1992 suggests greater uncertainty in the correlation estimate compared to the narrower interval in 2015, indicating more variability in the relationship between proportional expenditures and math average scores in the earlier period.

```{r}
hist(corResults1992, main = "Histogram of Bootstrapped Correlations(1992)", col = "purple", xlab = "Sample Correlations", breaks = 50)
abline(v = ci1992, lwd = 3, col = "darkgreen")
abline(v = cor.test(States1992$PROP_INSTRUCTION_EXPENDITURE, States1992$AVG_MATH)$conf.int, lwd = 3, col = "lightblue", lty = 2)
legend("topleft", c("Paramteric CI", "Boot CI"), lwd = 4, col = c("lightblue", "darkgreen"), lty = c(2, 1))

hist(corResults2015, main = "Histogram of Bootstrapped Correlations(2015)", col = "violet", xlab = "Sample Correlations", breaks = 50)
abline(v = ci2015, lwd = 3, col = "darkgreen")
abline(v = cor.test(States2015$PROP_INSTRUCTION_EXPENDITURE, States2015$AVG_MATH)$conf.int, lwd = 3, col = "lightblue", lty = 2)
legend("topleft", c("Parametric CI", "Boot CI"), lwd = 4, col = c("lightblue", "darkgreen"), lty = c(2, 1))
```
###Histogram analysis needs more###
The first histogram displays a distinct peak just below .2, indicating a concentration of bootstrapped correlation values around that point. The parametric confidence interval (teal line) appears narrower compared to the bootstrap confidence interval (green line).
In the second histogram, the distribution of bootstrapped correlations in 2015 exhibits a similar shape to the 1992 data, with a pronounced peak near 0.3. However, the peak appears slightly shifted to the right compared to 1992. The parametric confidence interval remains narrower than the bootstrap interval, consistent with the earlier observation.

# Analyzing Scores between Males and Females
## Descriptive Plots

```{r}
boxplot(States1992$AVG_MATH_M, States1992$AVG_MATH_F, main = "Box plot of Avg math scores in 1992", xlab = "Gender", ylab = "Score", col = c("lightblue", "lavender"), names = c("Male", "Females Scores"))
boxplot(States2015$AVG_MATH_M, States2015$AVG_MATH_F, main = "Box plot of Avg math scores in 2015", xlab = "Gender", ylab = "Score", col = c("lightblue", "lavender"), names = c("Male", "Females Scores"))
```

The first box plot displays the average math scores across all states in 1992, divided by gender. In this plot, both men and women have one outlier far below the other states with average scores below 240. It seems as though men have generally higher scores than women in math. The median, quartiles, min, and max are all higher for men then they are for women, indicating that men are performing better than women in math.

The second box plot displays the average math scores across all states in 2015, divided by gender. In this plot, unlike in 1992, men have an outlier further below, but it is only at a score of 260. Furthermore, women actually have an outlier further ABOVE, which did not occur in 1992. Additionally, it actually seems as though men and women have similar math scores, but women have a higher mean. Based on this plot and the former, it seems as though while scores for both men and women increased, the scores for women certainly increased the most. We can look into this further by utilizing the MATH_GENDER_DIF variable that we created to visualize the differences in scores between the genders.

```{r}
hist(States1992$MATH_GENDER_DIF, main = "Histogram of Differences in Avg Math Scores between Males and Females in 1992", xlab = "Differences in Scores(M-F)", col = "lightgreen", cex.main = 0.7)
hist(States2015$MATH_GENDER_DIF, main = "Histogram of Differences in Avg Math Scores between Males and Females in 2015", xlab = "Differences in Scores(M-F)", col = "darkgreen", cex.main = 0.7)
```
The first histogram displays the frequency distribution of the states' math gender difference scores in 1992. The distribution looks somewhat normal with a center at 0, however there's still a decent left skew. It still seems as though male scores tend to be higher since most states fall with a difference above 0 (meaning men have a higher score). Still, it seems more even than we would have believed from the box plots.

The second histogram displays the frequency distribution of the states' math gender difference scores in 2015. The distribution appears to be slightly skewed to the left, with the large majority of states falling below a difference of 0 (meaning that women tended to have a higher average score than men in. most states). This is certainly a change from 1992 where men had higher scores, but the data was more centered around 0 and normally distributed. This seems to be less normally distributed, as we will see in the qq plot.

```{r}
qqPlot(States1992$MATH_GENDER_DIF, main = "Quantile Plot of in Avg Math Score Diffs(Male - Females) in 1992", col = "lightgreen", pch = 19)
qqPlot(States2015$MATH_GENDER_DIF, main = "QQuantile Plot of in Avg Math Score Diffs(Male - Females) in 2015", col = "darkgreen", pch = 19)
```

This first normal quantile plot depicts the quantiles of a standard normal distribution, with the x-axis representing the norm quantiles and the y-axis showing the states' 1992 math gender difference scores. The points closely follow the diagonal line, suggesting that the gender difference scores are approximately normally distributed.*

Similar to the previous plot, this one shows the quantiles of the states' 2015 math gender difference scores plotted against the norm quantiles. The points appear to deviate slightly from the diagonal line, indicating a potential departure from normality, though the deviation is relatively small.

```{r}
#T=Tests
t.test(States1992$AVG_MATH_M, States1992$AVG_MATH_F)
t.test(States2015$AVG_MATH_M, States2015$AVG_MATH_F)
t.test(States1992$AVG_MATH, States2015$AVG_MATH)

```
The Two Sample t-tests were conducted to assess the differences in average math scores between male and female students in 1992 and 2015, as well as the difference in average math scores between the two years. In 1992, the difference in means between male (mean = 267.2857) and female (mean = 265.5000) average math scores was not statistically significant (t = 0.79624, p = 0.4282, df = 81.902), indicating that there was no significant gender gap in math performance that year. Similarly, in 2015, there was no significant difference in mean math scores between males (mean = 281.6471) and females (mean = 281.9020) (t = -0.17853, p = 0.8587, df = 99.178), suggesting that gender parity in math achievement was maintained over time. However, comparing average math scores between 1992 (mean = 266.2857) and 2015 (mean = 281.7255) revealed a statistically significant difference (t = -8.2789, p < 0.000000000005049, df = 71.068), with a substantial increase in mean scores over the years. This suggests an overall improvement in math performance across the sampled population from 1992 to 2015.

## Permutation Test

```{r}
set.seed(230)

diff <- median(States2015$AVG_MATH_M) - median(States2015$AVG_MATH_F)


n <- 10000 
fdiff <- rep(NA, n)
for (i in 1:n) {
  fakegender <- sample(c("M", "F"), 51, replace = T)
  fdiff[i] <- median(States2015$AVG_MATH_M[fakegender == "M"]) - median(States2015$AVG_MATH_F[fakegender == "F"])
}

hist(fdiff, main = "Permuted Sample Medians of Scores Between Genders", col = "turquoise", xlab = "Score Difference(M-F)", cex.main = .9)
abline(v = diff, col = "red", lwd = 2)
text(diff - 0.2, 750 , paste("Actual Diff in Medians =", round(diff,2)),srt = 90)
pval <- mean(abs(fdiff) >= abs(diff))
pval

```
The histogram displays the distribution of permuted sample medians for the difference in math scores between males and females across states in 2015. The distribution is heavily skewed to the left, with the peak around -1, indicating females tended to outperform males in most permuted samples. The vertical red line, representing the observed median difference in the original data, falls in the upper tail of this distribution. However, the p-value of 0.771 from the permutation test suggests the observed gender difference in median math scores is not statistically significant at a typical 0.05 level. The permutation test does not provide strong evidence against the null hypothesis of no gender difference in medians.

## Tests

```{r, eval=FALSE}
# Pearson correlation test between average math scores and scores for different racial groups
cor_test_results <- list()

racial_groups <- c("SCORE_NATIVE_AM", "SCORE_HISPANIC_LATINO", "SCORE_BLACK", "SCORE_WHITE", "SCORE_MULTIPLE_RACES")

for (group in racial_groups) {
  correlation <- cor.test(States2015$AVG_MATH, States2015[[group]])
  cor_test_results[[group]] <- correlation
}

# Print results
for (group in racial_groups) {
  cat("Correlation Test between AVG_MATH and", group, ":\n\n")
  print(cor_test_results[[group]])
  cat("\n")
}
```
We also performed Correlation Tests between the average Math score in 2015 and the Average math scores for the Individual Races to see how the correlations might vary between different races. We haven't included the evaluation of this code in this document to keep it brief, but the code is available in the rmd file. The following an outline of the statistics from the correlation tests. For Native American students (SCORE_NATIVE_AM), a positive correlation was found (cor = 0.3513), although it was not statistically significant at the 0.05 significance level (p-value = 0.06679). Hispanic/Latino students (SCORE_HISPANIC_LATINO) displayed a positive correlation as well (cor = 0.2962), which was statistically significant (p-value = 0.04091). Similarly, Black students (SCORE_BLACK) exhibited a positive correlation (cor = 0.4104), with statistical significance (p-value = 0.008523). White students (SCORE_WHITE) showed a stronger positive correlation (cor = 0.4674), which was highly statistically significant (p-value = 0.0005439). However, for students of multiple races (SCORE_MULTIPLE_RACES), the correlation was positive (cor = 0.3545) but not statistically significant at the 0.05 significance level (p-value = 0.08921). These results suggest varying degrees of correlation between average math scores and scores for different racial groups in 2015. Notably, statistically significant positive correlations are present for Hispanic/Latino, Black, and White racial groups, indicating that as average math scores increase, the scores for these racial groups tend to increase as well. However, the strength of these correlations varies among the different racial groups.



## Multiple Regression
In this multiple regression analysis, we aim to explore the relationship between average math scores (AVG_MATH) and scores for various racial/ethnic groups in the 2015 dataset. The variables considered include scores for Native American, Hispanic/Latino, Black, White, and students of multiple races. By employing multiple linear regression, we can assess how each racial/ethnic group's scores contribute to the overall average math performance while controlling for other variables. This process involves fitting a regression model to the data and examining the coefficients and significance levels of each predictor variable.
```{r}
mr <- lm(AVG_MATH ~  SCORE_NATIVE_AM + SCORE_HISPANIC_LATINO + SCORE_BLACK + SCORE_WHITE + SCORE_MULTIPLE_RACES, data = States2015)
summary(mr)

myResPlots2(mr)
```
This multiple linear regression analysis examinres the relationship between average math scores and scores for various racial/ethnic groups in 2015. The model demonstrates a strong explanatory power, with a multiple R-squared of 0.7613, indicating that approximately 76% of the variation in average math scores can be attributed to the predictor variables. Among the racial/ethnic groups, scores for Hispanic/Latino, Black, and White students emerge as significant predictors of average math scores, with coefficients indicating their respective impacts. Notably, Hispanic/Latino scores positively influence average math scores, while Black scores negatively affect them. However, scores for Native American and multiple race students do not show significant predictive power. These findings underscore the significance of racial/ethnic disparities in educational outcomes and emphasize the importance of targeted interventions to address them. There is no clear indication of heteroskedasticity in the Fits vs Studentized Residuals Plot.

# Scores by Region
Next, we wanted to look into if there was the region of the state has any significance on the average scores of the test. Before we got into that, lets look at boxplots of the scores by region to give us a general idea of the data.

```{r}
boxplot(AVG_MATH ~ Region, data = States2015, ylab = "Average Scores", main = "Boxplot")
```
This box plot illustrates the distribution of average math scores across different regions of the United States in 2015. The Midwest region displays the highest median score, with a compact interquartile range (IQR), suggesting less variability. The Northeast region follows with a slightly lower median score but a more spread-out IQR, indicating greater variability. Conversely, the South exhibits the lowest median score and the largest IQR, suggesting substantial variability across states. The West region falls between the Midwest and Northeast in median score, with a narrow IQR similar to the Midwest. These regional differences imply variations in math performance, with the Midwest performing the best and the South the poorest. However, further statistical analyses are needed to confirm these observations and account for potential confounding factors.

## ANOVA
```{r}
aov1 <- aov(AVG_MATH ~ Region, data = States2015)
summary(aov1)

TukeyHSD(aov1)
par(mar = c(5, 11, 4, 1))
plot(TukeyHSD(aov1), las = 1)

myResPlots2(aov1)
```
need analysis here


# ANALYSIS
poe-i think all the analysis here is redundant but could you double check

## ANALYSIS BASED ON PLOTS

The analysis of math scores from 1992 to 2015 reveals interesting trends regarding the impact of instructional expenditure and the dynamics of gender differences in math performance across U.S. states. In 1992, a positive correlation between total expenditure on instruction and average math scores was evident, although the data points displayed considerable variability. This trend became more pronounced by 2015, where the correlation strengthened and the data points clustered more tightly around the upward-sloping trend line, suggesting a more consistent effect of increased instructional spending on math scores. Moreover, when adjusting for the proportion of total expenditure allocated to instruction rather than absolute values, both years showed an even stronger positive correlation. This underscores the importance of proportionate spending in instruction as a significant predictor of math performance, hinting at the effectiveness of targeted investments in educational resources.

In terms of gender differences, the analysis does show a change over time. In 1992, men generally outperformed women in math, as indicated by higher medians and quartiles in the box plot distributions and a predominance of states showing a positive gender difference in favor of men. By 2015, however, this gap had not only narrowed but in many cases reversed, with the box plots showing comparable performance between genders and histograms indicating a leftward skew in gender difference scores — women now outperformed men in most states. This shift is further supported by the quantile-quantile plots, which suggest a move towards a less normal distribution in 2015, reflecting the notable improvement in women’s math scores relative to men's. This change could be attributed to various educational and societal developments over the 23 years that have increasingly leveled the playing field in STEM-related fields.

## ANALYSIS FROM TESTS 

The application of the Welch Two Sample t-test to assess gender differences in average math scores among states in 1992 and 2015 provides valuable insights into the evolution of educational outcomes. In 1992, the test yielded a t-value of 0.79624 with a degrees of freedom (df) of 81.902, resulting in a p-value of 0.4282. This high p-value indicates that the observed difference in average math scores between males and females (mean of x = 267.2857, mean of y = 265.5000) was not statistically significant. The confidence interval ranged from -2.675791 to 6.247219, spanning zero, further suggesting that the difference in means could feasibly be zero, thus supporting the null hypothesis that there is no significant difference between male and female math scores in 1992.

Fast forward to 2015, the Welch t-test results mirror the conclusions drawn in 1992 regarding gender differences, with even stronger evidence supporting the null hypothesis. The t-value of -0.17853 and a df of 99.178 produced a p-value of 0.8587, demonstrating that the difference in math scores between genders (mean of x = 281.6471, mean of y = 281.9020) remained statistically insignificant. The 95% confidence interval for this difference, from -3.087821 to 2.578017, also includes zero. These results indicate a continued absence of gender disparities in math performance across states, consistent with the narrowing gap observed in descriptive statistics from the same year.

Furthermore, examining the change in overall math scores from 1992 to 2015 across all states reveals a significant improvement. The Welch t-test comparing the average math scores of all states between these two years shows a substantial mean increase from 266.2857 in 1992 to 281.7255 in 2015. With a t-value of -8.2789 and a very small p-value close to zero, the test strongly rejects the null hypothesis, indicating a significant rise in math scores over this period. The confidence interval, ranging from -19.15833 to -11.72122, does not include zero, which solidifies the conclusion of a real, positive shift in educational performance.

Lastly, bootstrapped correlations provide further context to these findings, showing a range of possible correlation values between the variables studied. For 1992, the correlation interval spans from -0.1571800 to 0.4839411, and for 2015, it adjusts slightly to -0.04643523 to 0.53185830. These intervals suggest a variability in the strength and direction of the correlations, reflecting the complex interplay of factors affecting math scores across states over time. Such variability underscores the importance of considering multiple analytical approaches to understand trends thoroughly, especially in educational data where numerous socio-economic factors can influence outcomes.

# Conclusions and Summary

This comprehensive analysis of U.S. education data from 1992 to 2015 offers valuable insights into the dynamics of educational expenditure and academic performance at the state level. Our findings reveal a noticeable improvement in math scores over the period, underpinned by a stronger correlation between instructional spending and academic outcomes in 2015 compared to 1992. Particularly significant is the shift in gender performance in math; while men generally outscored women in 1992, the gap narrowed or even reversed in many states by 2015, highlighting a progressive change towards gender parity in education. Statistical tests confirm these observations, showing no significant gender-based differences in math scores by 2015. Furthermore, the analysis underscores the importance of proportional investment in instruction relative to total educational expenditure, suggesting that targeted funding is crucial for improving academic outcomes. These trends reflect broader educational advancements and shifts in policy focus over the twenty-three-year span, marking a positive shift towards more equitable and effective education systems across the U.S.
